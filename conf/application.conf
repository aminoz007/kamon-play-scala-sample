include "secure"

# db connections = ((physical_core_count * 2) + effective_spindle_count)
fixedConnectionPool = 5

repository.dispatcher {
  executor = "thread-pool-executor"
  throughput = 1
  thread-pool-executor {
    fixed-pool-size = ${fixedConnectionPool}
  }
}

kamon {
  environment.service = "Kamon Play REST Scala service"
}

# Docker
play.server.pidfile.path=/dev/null

# ======================================= #
# kamon-newrelic reference configuration  #
# ======================================= #

kamon.newrelic {
    # A New Relic Insights API Insert Key is required to send trace data to New Relic
    # https://docs.newrelic.com/docs/apis/get-started/intro-apis/types-new-relic-api-keys#insert-key-create
    nr-insights-insert-key = ${?INSIGHTS_INSERT_KEY}
}

# =========================================== #
# Kamon APM Reporter Reference Configuration  #
# =========================================== #

kamon.apm {
  # API Key. You can find it in the Administration section in Kamon APM.
  api-key = ${?KAMON_APM_API_KEY} # TODO add KAMON_APM_API_KEY to vault for grand central deployments

  # Decide whether to send spans to Kamon APM or not. If a value for the `enableTracing` parameter is provided
  # when initializing the KamonApmReporter, that value will override this setting. For example:
  #
  #   Kamon.addReporter(new KamonApmReporter())                     // Uses this setting value.
  #   Kamon.addReporter(new KamonApmReporter(enableTracing = true)) // Sends spans, regardless of this setting.
  #
  enable-tracing = yes

  # Your application version.
  app-version = "N/A"

  # Where to POST data to.
  ingestion-api = "https://ingestion.apm.kamon.io/v1"

  # Define proxy to be used for reaching the Kamon APM API.
  proxy {

    # Specify proxy type to be used. The possible values are:
    #   - system: uses whatever proxy configuration is set on the JVM.
    #   - https: use a HTTPS proxy. The host and port are controlled with the settings bellow.
    #   - socks: use a SOCKS proxy. The host and port are controlled with the settings bellow.
    type = "system"

    # Proxy Host
    host = "localhost"

    # Proxy Port
    port = 443
  }

  # Define how many times to retry each type of request sent to the Kamon APM API and for how long to back off
  # in case of failed requests.
  retries {

    # For notifications of application startup.
    boot = 3

    # For metrics data.
    ingestion = 20

    # For notifications of application shutdown.
    shutdown = 0

    # For tracing data.
    tracing = 20

    # How long to wait before retrying a API call.
    backoff = 30 seconds
  }

  # Settings for the HTTP client used by the Kamon API reporters.
  client {

    # Minimum amount of time between requests to Kamon APM.
    backoff =  5 seconds

    # HTTP Client actions timeout.
    timeouts {
      connection = 10 seconds
      read = 10 seconds
    }
  }
}

# ===============================#
# Kanela reference configuration #
# ===============================#

kanela {
  # Enables an instrumentation listener that is informed about events that occur during an instrumentation process and
  # logs the events in console and a rolling file.
  debug-mode = false

  instrumentation-registry {
    enabled = true
  }
  # Enables the kanela banner at startup.
  show-banner = true
  # The log verbosity level: TRACE|DEBUG|INFO|WARNING|ERROR|OFF.
  log-level = "INFO"
  # Just a place holder to ensure that the key is always available.
  modules {
    # module-name {
    #     # Name
    #     name = "descriptive-name"
    #     # If the module is enabled (optional).
    #     enabled = true|false (optional)
    #     # The execution order between modules (optional).
    #     order = 1
    #     #  Configuration of the bootstrap classloader injection feature (optional).
    #     bootstrap-injection {
    #       # If the bootstrap injection is enabled (optional).
    #       enabled = true|false
    #       # List of helper classes to be injected into bootstrap classloader.
    #       helper-class-names = []
    #     }
    #     # Enable class file version validator. By default only class files > to JAVA 5 are supported.
    #     enable-class-file-version-validator = true
    #     # Temporary directory for store the intrumentations to be injected into the bootstrap classloader (optional).
    #     temp-dir-prefix = "tmp"
    #     # If the module can be stopped in runtime.
    #     stoppable = true|false (optional)
    #     # Enable restrictions imposed by most VMs and also HotSpot..
    #     disable-class-format-changes = "true|false" (optional)
    #     # List of fully qualified name of the implementation of kanela.agent.api.instrumentation.InstrumentationBuilderr.
    #     instrumentations = []
    #     # Excludes all types that matches the list of patterns. e.g. org.apache. *
    #     exclude = []
    #     # Only instruments types that are within the list of patterns. e.g. javax.*
    #     within = []
    # }
  }
  # Listener that allows save the instrumented classes in a folder or jar.
  class-dumper {
    # Enables the class dumper.
    enabled = false
    # Default dir.
    dir = ${user.home}"/kanela-agent/dump"
    # By default build a jar containing all instrumented classes.
    create-jar = true
    # Default jar name.
    jar-name = "instrumented-classes"
  }
  # The circuit breaker takes two parameters into account (heap usage and cpu process percentage after an Old CG) to determine when it should trip.
  circuit-breaker {
    # Enables the circuit breaker.
    enabled = false
    # The default values for these thresholds are percentages
    # percentage of free memory after Old GC
    free-memory-threshold = 20.0
    # percentage of process cpu usage after Old GC
    gc-process-cpu-threshold = 10.0
  }
  # Listener that is subscribed to JMX GC events and gather information after a GC Event.
  gc-listener {
    # If the listener should log GC information afer a Old GC.
    log-after-gc-run = false
  }

  # Allows replacing the contents of a class with the contents of another. Since the replacer configuration is a list,
  # it must be specified on the following format:
  #
  #   kanela.class-replacer.replace = ${?kanela.class-replacer.replace} "Target=>Replacement"
  #
  # Where the "Target" section is the FQCN of the class to be replaced and "Replacement" is the FQCN of the class that
  # will take the Target's place.
  #
  class-replacer {
    replace = [] ${?kanela.class-replacer.replace}
  }
}

# ======================================== #
# kamon-zipkin reference configuration #
# ======================================== #

kamon.trace.join-remote-parents-with-same-span-id = yes
kamon.zipkin {

  # Hostname and port where the Zipkin Server is running
  # host = "zipkin" is from the readme example running the app and zipkin instances in Docker containers using the same
  # custom network `--network kamon_network` where the zipkin container is named using `--name kamon_network`
  # this should be configured different if run on Grand Central
  host = "zipkin"
  port = 9411

  # Decides whether to use HTTP or HTTPS when connecting to Zipkin
  protocol = "http"
}

# ================================== #
# Kamon-Akka Reference Configuration #
# ================================== #

kamon.instrumentation.akka {

  # If ask-pattern-timeout-warning is enabled, a WARN level log message will be generated if a Future generated by the
  # "ask" pattern fails with an AskTimeoutException and the log message will contain information depending of the
  # selected strategy. The possible values are:
  #
  #   - off: nothing gets logged.
  #   - lightweight: logs a warning when a timeout is reached using source location.
  #   - heavyweight: logs a warning when a timeout is reached using a stack trace captured at the moment the future was created.
  #
  ask-pattern-timeout-warning = off

  # Automatically creates Actor Groups that contain all actors of the same Class at the same level of the Actor System
  # tree. This will only be applied to actors that are not individually tracked, that are not part of another groups and
  # that match the "auto-grouping" filter bellow. This allows, for example, to automatically get metrics from anonymous
  # actors without messing with filters and risking cardinality explosions.
  #
  auto-grouping = on

  # Filters control how and if the instrumentation will track the behavior of Akka Actors, Routers, Dispatchers and
  # Actor Groups. All filters have two groups of patterns: includes and excludes; inputs matching at least one of the
  # includes patterns and none of the excludes patterns will be accepted. You can read more about filters on the Kamon
  # documentation: https://kamon.io/docs/latest/core/utilities/
  #
  # The test string for the filters is always starting with the Actor System name, followed by the path to the
  # component being tested. For example, when testing for a "test" actor created at the root of the "akka-example" Actor
  # System, the test string for the filter will be "akka-example/user/test" and, when testing the default dispatcher for
  # that same Actor System the test string for the filters will be "akka-example/akka.actor.default-dispatcher".
  #
  filters {

    # Defines actor groups and the filters that match all actors that should be part of that group. To define a new
    # group, add a configuration like the following:
    #
    #   kamon.instrumentation.akka.filters.groups {
    #     worker-actors {
    #       includes = [ "my-system/user/application/worker-*", "my-system/user/workers/**" ]
    #       excludes = [ ]
    #     }
    #   }
    #
    # The configuration key immediately inside the "groups" path corresponds to the group name and the configuration
    # inside of it should contain a Kamon filter (with the includes/excludes settings).
    groups {

      # Special filter used for auto-grouping. Auto-grouping will only act on actors that are not being explicitly
      # tracked as inidividual actors, do not belong to any other groups and match this filter.
      #
      auto-grouping {
        includes = [ "*/user/**" ]
        excludes = [ ]
      }
    }

    # Decids how Actors are going to be tracked and traced.
    #
    actors {

      # Decides whether the "**" filter can be used for the "track" and "start-trace" filters. Historically, users have
      # beeing using the "**" filters during testing because simplicitly and then go to production with the same filter
      # configuration which usually results in cardinality explosions and/or OOM errors. Since the introduction of auto
      # grouping, the instrumentation will do a much better work at providing metrics out of the box and forbids the use
      # of the "doomsday" wildcard. Enable and use at your own risk.
      #
      doomsday-wildcard = off

      # Decides which actors will have metric tracking enabled. Beware that most of the time what you really need is to
      # track Actor groups instead of individual actors because wildly targetting actors can lead to cardinality issues.
      #
      track {
        includes = [ ]
        excludes = [ "*/system/**", "*/user/IO-**" ]
      }

      # Decides which actors generate Spans for the messages they process, given that there is already an ongoing trace
      # in the Context of the processed message (i.e. there is a Sampled Span in the Context).
      #
      trace {
        includes = [ "*/user/**", "*/system/sharding**" ]
        excludes = [ ]
      }

      # Decides which actors generate Spans for the messages they process, even if that requires them to start a new
      # trace. Use with care, starting traces with a broad filter (e.g. using includes = [ "**" ]) can generate a huge
      # amount of traces from scheduled actions and underlying system components that most likely will not improve
      # observability of the system and burry useful traces underneath the noise.
      #
      start-trace {
        includes = [ ]
        excludes = [ ]
      }
    }

    # Decides which routers should have metric tracking enabled.
    #
    routers {
      includes = [ ]
      excludes = [ ]
    }

    # Decides which dispatchers should have metric tracking enabled.
    #
    dispatchers {
      includes = [ "**" ]
      excludes = [ ]
    }
  }

  remote {

    # Controls whether tracking of the serialization, deserialization and message size metrics should be tracked for
    # messages going to and coming from a remoting channel.
    track-serialization-metrics = true
  }

  cluster-sharding {

    # Sets the interval at which the Shard metrics (sampling of hosted entities and processed messages across all
    # shards) will be sampled.
    shard-metrics-sample-interval = ${kamon.metric.tick-interval}
  }
}

# ===================================== #
# kamon-logback reference configuration #
# ===================================== #

kamon.instrumentation.logback {

  # Controls if and how Context data should be copied into the MDC while events are being logged.
  #
  mdc {

    # MDC keys used to store the current trace and span identifiers. These keys will only be copied if there is a
    # non-empty Span in the Context associated with the logged event.
    trace-id-key = "kamonTraceId"
    span-id-key = "kamonSpanId"

    # Enables copying of Context information into the MDC. Please note that if you only want to include certain Context
    # information in your log patterns you are better off by simply using the conversion rules available under the
    # "tools" package. Copying data into the MDC is required only in cases where third-party tooling expects data from
    # the MDC to be extracted.
    #
    copy {

      # Controls whether Context information should be copied into the MDC or not.
      enabled = yes

      # Controls whether Context tags should be copied into the MDC.
      tags = yes

      # Contains the names of all Context entries that should be copied into the MDC.
      entries = [ ]
    }
  }
}

###############################################
#   Kamon Executors Reference Configuration   #
###############################################

kamon.instrumentation.executor {

  # Interval at which all instrumented executor metrics will be sampled.
  sample-interval = 500 milliseconds

}

# ======================================= #
# Kamon-Http4s Reference Configuration #
# ======================================= #

kamon.instrumentation.http4s {

  # Settings to control the HTTP Server instrumentation.
  #
  # IMPORTANT: Besides the "initial-operation-name" and "unhandled-operation-name" settings, the entire configuration of
  # the HTTP Server Instrumentation is based on the constructs provided by the Kamon Instrumentation Common library
  # which will always fallback to the settings found under the "kamon.instrumentation.http-server.default" path. The
  # default settings have been included here to make them easy to find and understand in the context of this project and
  # commented out so that any changes to the default settings will actually have effect.
  #
  server {

    #
    # Configuration for HTTP context propagation.
    #
    propagation {

      # Enables or disables HTTP context propagation on this HTTP server instrumentation. Please note that if
      # propagation is disabled then some distributed tracing features will not be work as expected (e.g. Spans can
      # be created and reported but will not be linked across boundaries nor take trace identifiers from tags).
      #enabled = yes

      # HTTP propagation channel to b used by this instrumentation. Take a look at the kamon.propagation.http.default
      # configuration for more details on how to configure the detault HTTP context propagation.
      channel = "default"


    }


    #
    # Configuration for HTTP server metrics collection.
    #
    metrics {

      # Enables collection of HTTP server metrics. When enabled the following metrics will be collected, assuming
      # that the instrumentation is fully compliant:
      #
      #   - http.server.requets
      #   - http.server.request.active
      #   - http.server.request.size
      #   - http.server.response.size
      #   - http.server.connection.lifetime
      #   - http.server.connection.usage
      #   - http.server.connection.open
      #
      # All metrics have at least three tags: component, interface and port. Additionally, the http.server.requests
      # metric will also have a status_code tag with the status code group (1xx, 2xx and so on).
      #
      #enabled = yes
    }


    #
    # Configuration for HTTP request tracing.
    #
    tracing {

      # Enables HTTP request tracing. When enabled the instrumentation will create Spans for incoming requests
      # and finish them when the response is sent back to the clients.
      #enabled = yes

      # Select a context tag that provides a preferred trace identifier. The preferred trace identifier will be used
      # only if all these conditions are met:
      #   - the context tag is present.
      #   - there is no parent Span on the incoming context (i.e. this is the first service on the trace).
      #   - the identifier is valid in accordance to the identity provider.
      #preferred-trace-id-tag = "none"

      # Enables collection of span metrics using the `span.processing-time` metric.
      #span-metrics = on

      # Select which tags should be included as span and span metric tags. The possible options are:
      #   - span: the tag is added as a Span tag (i.e. using span.tag(...))
      #   - metric: the tag is added a a Span metric tag (i.e. using span.tagMetric(...))
      #   - off: the tag is not used.
      #
      tags {

        # Use the http.url tag.
        #url = span

        # Use the http.method tag.
        #method = metric

        # Use the http.status_code tag.
        #status-code = metric

        # Copy tags from the context into the Spans with the specified purpouse. For example, to copy a customer_type
        # tag from the context into the HTTP Server Span created by the instrumentation, the following configuration
        # should be added:
        #
        # from-context {
        #   customer_type = span
        # }
        #
        from-context {

        }
      }

      # Controls writing trace and span identifiers to HTTP response headers sent by the instrumented servers. The
      # configuration can be set to either "none" to disable writing the identifiers on the response headers or to
      # the header name to be used when writing the identifiers.
      response-headers {

        # HTTP response header name for the trace identifier, or "none" to disable it.
        #trace-id = "trace-id"

        # HTTP response header name for the server span identifier, or "none" to disable it.
        #span-id = none
      }

      # Custom mappings between routes and operation names.
      operations {

        # The default operation name to be used when creating Spans to handle the HTTP server requests. In most
        # cases it is not possible to define an operation name right at the moment of starting the HTTP server Span
        # and in those cases, this operation name will be initially assigned to the Span. Instrumentation authors
        # should do their best effort to provide a suitable operation name or make use of the "mappings" facilities.
        #default = "http.server.request"

        # Provides custom mappings from HTTP paths into operation names. Meant to be used in cases where the bytecode
        # instrumentation is not able to provide a sensible operation name that is free of high cardinality values.
        # For example, with the following configuration:
        #   mappings {
        #     "/organization/*/user/*/profile" = "/organization/:orgID/user/:userID/profile"
        #     "/events/*/rsvps" = "EventRSVPs"
        #   }
        #
        # Requests to "/organization/3651/user/39652/profile" and "/organization/22234/user/54543/profile" will have
        # the same operation name "/organization/:orgID/user/:userID/profile".
        #
        # Similarly, requests to "/events/aaa-bb-ccc/rsvps" and "/events/1234/rsvps" will have the same operation
        # name "EventRSVPs".
        #
        # The patterns are expressed as globs and the operation names are free form.
        #
        mappings {

        }
      }
    }
  }

  # Settings to control the HTTP Client instrumentation
  #
  # IMPORTANT: The entire configuration of the HTTP Client Instrumentation is based on the constructs provided by the
  # Kamon Instrumentation Common library which will always fallback to the settings found under the
  # "kamon.instrumentation.http-client.default" path. The default settings have been included here to make them easy to
  # find and understand in the context of this project and commented out so that any changes to the default settings
  # will actually have effect.
  #
  client {

    #
    # Configuration for HTTP context propagation.
    #
    propagation {

      # Enables or disables HTTP context propagation on this HTTP server instrumentation. Please note that if
      # propagation is disabled then some distributed tracing features will not be work as expected (e.g. Spans can
      # be created and reported but will not be linked across boundaries nor take trace identifiers from tags).
      #enabled = yes

      # HTTP propagation channel to b used by this instrumentation. Take a look at the kamon.propagation.http.default
      # configuration for more details on how to configure the detault HTTP context propagation.
      #channel = "default"
    }

    tracing {

      # Enables HTTP request tracing. When enabled the instrumentation will create Spans for outgoing requests
      # and finish them when the response is received from the server.
      #enabled = yes

      # Enables collection of span metrics using the `span.processing-time` metric.
      #span-metrics = on

      # Select which tags should be included as span and span metric tags. The possible options are:
      #   - span: the tag is added as a Span tag (i.e. using span.tag(...))
      #   - metric: the tag is added a a Span metric tag (i.e. using span.tagMetric(...))
      #   - off: the tag is not used.
      #
      tags {

        # Use the http.url tag.
        #url = span

        # Use the http.method tag.
        #method = metric

        # Use the http.status_code tag.
        #status-code = metric

        # Copy tags from the context into the Spans with the specified purpouse. For example, to copy a customer_type
        # tag from the context into the HTTP Server Span created by the instrumentation, the following configuration
        # should be added:
        #
        # from-context {
        #   customer_type = span
        # }
        #
        from-context {

        }
      }

      operations {

        # The default operation name to be used when creating Spans to handle the HTTP client requests. The HTTP
        # Client instrumentation will always try to use the HTTP Operation Name Generator configured bellow to get
        # a name, but if it fails to generate it then this name will be used.
        #default = "http.client.request"

        # FQCN for a HttpOperationNameGenerator implementation, or ony of the following shorthand forms:
        #   - hostname: Uses the request Host as the operation name.
        #   - method: Uses the request HTTP method as the operation name.
        #
        name-generator = "kamon.http4s.PathOperationNameGenerator"
      }
    }
  }
}

# ========================================== #
# kamon-scala-future Reference Configuration #
# ========================================== #

kamon.instrumentation.futures.scala {

  # Settings controlling the behavior of the Delayed Spans created by the Scala Future instrumentation
  trace {

    # Controls metrics tracking on all Spans generated by the Scala Future Instrumentation. When enabled, the default
    # metrics for Delayed Spans will be tracked:
    #
    #   - span.elapsed-time: measures the time since a future or callback was created until it finished executing.
    #   - span.wait-time:
    #   - span.processing-time: n
    track-span-metrics = yes

    # Controls tracking of Delayed Span-specific metrics on all Spans generated by the Scala Future Instrumentation.
    track-delayed-span-metrics = yes
  }
}

# ========================================== #
# kamon-system-metrics Reference Configuration #
# ========================================== #


kamon.instrumentation.system {
  jvm {

  }

  process {
    hiccup-monitor-interval = 1 millisecond
  }

  host {
    storage {

      # Decides which file system types will be selected for tracking usage and activity metrics. By default we are
      # excluding types associated with Docker and Ubuntu Snaps which would usually generate irrelevant metrics.
      tracked-mount-types {
        includes = [ "**" ]
        excludes = ["squashfs", "tmpfs", "aufs"]
      }
    }

    network {

      # Decides which network interfaces will be selected for tracking network activity metrics. By default we are
      # excluding network interface names known to be associated with Docker.
      tracked-interfaces {
        includes = [ "**" ]
        excludes = [ "docker0", "br-*" ]
      }
    }
  }
}

# ================================== #
# kamon-play reference configuration #
# ================================== #
# Play Framework secret key to run Play app in production mode
# https://www.playframework.com/documentation/2.7.x/ApplicationSecret
play.http.secret.key = ${?APPLICATION_SECRET}

kamon.instrumentation.play.http {

  server {

    #
    # Configuration for HTTP context propagation.
    #
    propagation {

      # Enables or disables HTTP context propagation on this HTTP server instrumentation. Please note that if
      # propagation is disabled then some distributed tracing features will not be work as expected (e.g. Spans can
      # be created and reported but will not be linked across boundaries nor take trace identifiers from tags).
      enabled = yes

      # HTTP propagation channel to b used by this instrumentation. Take a look at the kamon.propagation.http.default
      # configuration for more details on how to configure the detault HTTP context propagation.
      channel = "default"
    }


    #
    # Configuration for HTTP server metrics collection.
    #
    metrics {

      # Enables collection of HTTP server metrics. When enabled the following metrics will be collected, assuming
      # that the instrumentation is fully compliant:
      #
      #   - http.server.requets
      #   - http.server.request.active
      #   - http.server.request.size
      #   - http.server.response.size
      #   - http.server.connection.lifetime
      #   - http.server.connection.usage
      #   - http.server.connection.open
      #
      # All metrics have at least three tags: component, interface and port. Additionally, the http.server.requests
      # metric will also have a status_code tag with the status code group (1xx, 2xx and so on).
      #
      enabled = yes
    }


    #
    # Configuration for HTTP request tracing.
    #
    tracing {

      # Enables HTTP request tracing. When enabled the instrumentation will create Spans for incoming requests
      # and finish them when the response is sent back to the clients.
      enabled = yes

      # Select a context tag that provides a preferred trace identifier. The preferred trace identifier will be used
      # only if all these conditions are met:
      #   - the context tag is present.
      #   - there is no parent Span on the incoming context (i.e. this is the first service on the trace).
      #   - the identifier is valid in accordance to the identity provider.
      #preferred-trace-id-tag = "none"

      # Enables collection of span metrics using the `span.processing-time` metric.
      span-metrics = on

      # Select which tags should be included as span and span metric tags. The possible options are:
      #   - span: the tag is added as a Span tag (i.e. using span.tag(...))
      #   - metric: the tag is added a a Span metric tag (i.e. using span.tagMetric(...))
      #   - off: the tag is not used.
      #
      tags {

        # Use the http.url tag.
        #url = span

        # Use the http.method tag.
        #method = metric

        # Use the http.status_code tag.
        #status-code = metric

        # Copy tags from the context into the Spans with the specified purpouse. For example, to copy a customer_type
        # tag from the context into the HTTP Server Span created by the instrumentation, the following configuration
        # should be added:
        #
        # from-context {
        #   customer_type = span
        # }
        #
        from-context {

        }
      }

      # Controls writing trace and span identifiers to HTTP response headers sent by the instrumented servers. The
      # configuration can be set to either "none" to disable writing the identifiers on the response headers or to
      # the header name to be used when writing the identifiers.
      response-headers {

        # HTTP response header name for the trace identifier, or "none" to disable it.
        #trace-id = "trace-id"

        # HTTP response header name for the server span identifier, or "none" to disable it.
        #span-id = none
      }

      # Custom mappings between routes and operation names.
      operations {

        # The default operation name to be used when creating Spans to handle the HTTP server requests. In most
        # cases it is not possible to define an operation name right at the moment of starting the HTTP server Span
        # and in those cases, this operation name will be initially assigned to the Span. Instrumentation authors
        # should do their best effort to provide a suitable operation name or make use of the "mappings" facilities.
        #default = "http.server.request"

        # The operation name to be assigned when an application cannot find any route/endpoint/controller to handle
        # a given request. Depending on the instrumented framework, it might be possible to apply this operation
        # name automatically or not, check the frameworks' instrumentation docs for more details.
        #unhandled = "unhandled"

        # Provides custom mappings from HTTP paths into operation names. Meant to be used in cases where the bytecode
        # instrumentation is not able to provide a sensible operation name that is free of high cardinality values.
        # For example, with the following configuration:
        #   mappings {
        #     "/organization/*/user/*/profile" = "/organization/:orgID/user/:userID/profile"
        #     "/events/*/rsvps" = "EventRSVPs"
        #   }
        #
        # Requests to "/organization/3651/user/39652/profile" and "/organization/22234/user/54543/profile" will have
        # the same operation name "/organization/:orgID/user/:userID/profile".
        #
        # Similarly, requests to "/events/aaa-bb-ccc/rsvps" and "/events/1234/rsvps" will have the same operation
        # name "EventRSVPs".
        #
        # The patterns are expressed as globs and the operation names are free form.
        #
        mappings {

        }
      }
    }
  }

  client {

    #
    # Configuration for HTTP context propagation.
    #
    propagation {

      # Enables or disables HTTP context propagation on this HTTP server instrumentation. Please note that if
      # propagation is disabled then some distributed tracing features will not be work as expected (e.g. Spans can
      # be created and reported but will not be linked across boundaries nor take trace identifiers from tags).
      enabled = yes

      # HTTP propagation channel to b used by this instrumentation. Take a look at the kamon.propagation.http.default
      # configuration for more details on how to configure the detault HTTP context propagation.
      channel = "default"
    }

    tracing {

      # Enables HTTP request tracing. When enabled the instrumentation will create Spans for outgoing requests
      # and finish them when the response is received from the server.
      #enabled = yes

      # Enables collection of span metrics using the `span.processing-time` metric.
      #span-metrics = on

      # Select which tags should be included as span and span metric tags. The possible options are:
      #   - span: the tag is added as a Span tag (i.e. using span.tag(...))
      #   - metric: the tag is added a a Span metric tag (i.e. using span.tagMetric(...))
      #   - off: the tag is not used.
      #
      tags {

        # Use the http.url tag.
        #url = span

        # Use the http.method tag.
        #method = metric

        # Use the http.status_code tag.
        #status-code = metric

        # Copy tags from the context into the Spans with the specified purpouse. For example, to copy a customer_type
        # tag from the context into the HTTP Server Span created by the instrumentation, the following configuration
        # should be added:
        #
        # from-context {
        #   customer_type = span
        # }
        #
        from-context {

        }
      }

      operations {

        # The default operation name to be used when creating Spans to handle the HTTP client requests. The HTTP
        # Client instrumentation will always try to use the HTTP Operation Name Generator configured bellow to get
        # a name, but if it fails to generate it then this name will be used.
        #default = "http.client.request"

        # FQCN for a HttpOperationNameGenerator implementation, or ony of the following shorthand forms:
        #   - hostname: Uses the request Host as the operation name.
        #   - method: Uses the request HTTP method as the operation name.
        #
        #name-generator = "method"
      }
    }
  }
}

# Registers the Guice module on Play, which ensures that Kamon will be reconfigured with Play's configuration
# and all Kamon modules will be started appropriately.
play.modules.enabled += "kamon.instrumentation.play.GuiceModule"

# ======================================== #
# kamon-prometheus reference configuration #
# ======================================== #
kamon.prometheus {

  # Enable or disable publishing the Prometheus scraping enpoint using a embedded server.
  start-embedded-http-server = yes

  # Enable of disable including tags from kamon.prometheus.environment as labels
  include-environment-tags = yes

  buckets {
    default-buckets = [
      10,
      30,
      100,
      300,
      1000,
      3000,
      10000,
      30000,
      100000
    ]

    time-buckets = [
      0.005,
      0.01,
      0.025,
      0.05,
      0.075,
      0.1,
      0.25,
      0.5,
      0.75,
      1,
      2.5,
      5,
      7.5,
      10
    ]

    information-buckets = [
      512,
      1024,
      2048,
      4096,
      16384,
      65536,
      524288,
      1048576
    ]

    # Per metric overrides are possible by specifying the metric name and the histogram buckets here
    custom {
      # "akka.actor.processing-time" = [0.1, 1.0, 10.0]
    }
  }


  embedded-server {

    # Hostname and port used by the embedded web server to publish the scraping enpoint.
    hostname = 0.0.0.0
    port = 9095
  }

  # Specify metric name overrides here
  metric-overrides {
  }
}

# custom tags on Prometheus metrics
kamon.environment.tags {
  user = "newrelic"
  env = dev
  foo = bar
}

kamon.context.codecs {

  # Codecs to be used when propagating a Context through a HTTP Headers transport.
  http-headers-keys {
    span = "kamon.trace.SpanCodec$B3"
  }

  # Codecs to be used when propagating a Context through a Binary transport.
  binary-keys {
    span = "kamon.trace.SpanCodec$Colfer"
  }
}